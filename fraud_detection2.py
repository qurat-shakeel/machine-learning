# -*- coding: utf-8 -*-
"""fraud_detection2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19p7ZH4xzwc08JKwGszscSKvwAizcSEWH
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.feature_selection import SelectKBest, f_classif
from imblearn.over_sampling import SMOTE
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

df = pd.read_csv("frauddetection.csv")

X = df.drop(['Class'], axis=1)
y = df['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Handle imbalanced data using SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

selector = SelectKBest(f_classif, k=20)
X_train_smote = selector.fit_transform(X_train_smote, y_train_smote)
X_test = selector.transform(X_test)

scaler = StandardScaler()
X_train_smote = scaler.fit_transform(X_train_smote)
X_test = scaler.transform(X_test)

def create_model():
    model = Sequential([
        Dense(64, input_shape=(X_train_smote.shape[1],), activation='relu'),
        Dropout(0.5),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(64, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Hyperparameters
batch_size = 32
epochs = 10

model = create_model()

# Implement early stopping to avoid overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)



model.fit(X_train_smote, y_train_smote, epochs=epochs, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping])

y_pred_prob = model.predict(X_test)
y_pred = (y_pred_prob > 0.5).astype("int32")

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

print("Optimized Neural Network Model Evaluation")
print("Accuracy: {:.4f}".format(accuracy))
print("Precision: {:.4f}".format(precision))
print("Recall: {:.4f}".format(recall))
print("F1 Score: {:.4f}".format(f1))
print("Confusion Matrix:\n", conf_matrix)
print("\nClassification Report:\n", classification_report(y_test, y_pred))

threshold = 0.3
y_pred_adjusted = (y_pred_prob > threshold).astype("int32")


accuracy_adj = accuracy_score(y_test, y_pred_adjusted)
precision_adj = precision_score(y_test, y_pred_adjusted)
recall_adj = recall_score(y_test, y_pred_adjusted)
f1_adj = f1_score(y_test, y_pred_adjusted)
conf_matrix_adj = confusion_matrix(y_test, y_pred_adjusted)

print("\nEvaluation with Adjusted Threshold")
print("Accuracy: {:.4f}".format(accuracy_adj))
print("Precision: {:.4f}".format(precision_adj))
print("Recall: {:.4f}".format(recall_adj))
print("F1 Score: {:.4f}".format(f1_adj))
print("Confusion Matrix:\n", conf_matrix_adj)
print("\nClassification Report:\n", classification_report(y_test, y_pred_adjusted))