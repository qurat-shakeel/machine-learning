# -*- coding: utf-8 -*-
"""creditcard_fraud.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17wGT4C2d-E4rQwZwgE30TCff4pIpIzpq
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler

df = pd.read_csv('creditcard.csv')
df

print(df.head())

print(df.info())

print(df.describe())

# Count the number of fraud and non-fraud transactions
fraud_count = df['Class'].value_counts()
fraud_count

missing_values = df.isnull().sum()
print("Missing values in each column:\n", missing_values[missing_values > 0])

df.fillna(df.mean(), inplace=True)

df.dropna(inplace=True)

print(df.duplicated().sum())

# Remove duplicates
df.drop_duplicates(inplace=True)

# Count the number of fraud and non-fraud transactions
fraud_count = df['Class'].value_counts()

# Ensure the data is in a 1D array-like structure
labels = ['Non-Fraud', 'Fraud']
sizes = [fraud_count[0], fraud_count[1]]

print("Sizes:", sizes)
print("Labels:", labels)

# Plot the pie chart
plt.figure(figsize=(8, 8))
plt.pie(sizes, labels=labels, autopct='%1.1f%%')

# Equal aspect ratio ensures that pie is drawn as a circle.
plt.axis('equal')
plt.title('Fraud vs Non-Fraud Transactions')
plt.show()

# Print column names to check available columns
print("Column names in the dataset:", df.columns)

# Define features and target
X = df.drop(columns=['Class'])
y = df['Class']

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

from sklearn.model_selection import train_test_split
# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

pip install lazypredict

from lazypredict.Supervised import LazyClassifier

# Use LazyPredict to evaluate multiple models
clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)
models, predictions = clf.fit(X_train, X_test, y_train, y_test)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

# Build the model
model = Sequential([
    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.5),
    Dense(16, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test Loss: {test_loss}')
print(f'Test Accuracy: {test_accuracy}')